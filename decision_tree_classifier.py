# -*- coding: utf-8 -*-
"""Decision Tree Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nNqp5jLQ8HmA08VPz2lxDpj6_CC9l3gI

<center><h1> Atelier : Machine Learning  ML</h1></center>
<center><h3>Decision  Tree Classifier</h3></center>
<center><h3>20 Décembre 2022</h3></center>

---

# **Importation des libraries**
Commençons par charger les libraries.
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

"""# **Chargement des données**
Charger l'ensemble de données Pima Indian Diabetes requis à l'aide de la fonction CSV de lecture de pandas. Vous pouvez le télécharger sur moodle.
"""

# load dataset
pima = pd.read_csv("/content/diabetes.csv")

pima.head()

"""# **Sélection des caracteristiques et fractionnement des données**
Ici, nous devons diviser les colonnes données en deux types de variables dépendantes (ou variables cibles) et variables indépendantes (ou variables de caractéristiques).

Et également diviser l'ensemble de données en un ensemble d'apprentissage et un ensemble de test.

"""

feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age','Glucose','BloodPressure','DiabetesPedigreeFunction']
X = pima[feature_cols] # Features
y = pima.Outcome # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

"""# **Construction d'un modèle d'arbre de décision**
Créons un modèle d'arbre de décision à l'aide de Scikit-learn.
"""

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

"""# **L'évaluation du modèle**
Estimons avec quelle précision le classificateur ou le modèle peut prédire sur les données de testes.
"""

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""# **Visualisation**
Vous pouvez utiliser la fonction *export_graphviz* de *Scikit-learn* pour afficher l'arbre dans un notebook *Jupyter*.

La fonction *export_graphviz* convertit le classificateur d'arbre de décision en fichier *DOT* et pydotplus convertit ce fichier *DOT* en png ou sous forme affichable sur *Jupyter*.
"""

from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus

dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('diabetes.png')
Image(graph.create_png())

"""# **Optimisation des performances**
**criterion** : Ce paramètre nous permet d'utiliser la mesure de sélection d'attribut. Les critères pris en charge sont "*gini*" pour l'indice de Gini et "*entropy*" pour le gain d'information.

**splitter** : Ce paramètre nous permet de choisir la stratégie de split, Les stratégies prises en charge sont « best » pour choisir la meilleure répartition et « random » pour choisir la meilleure répartition aléatoire.

**max_depth** : int ou None, (la valeur par defaut est *None*) La profondeur maximum de l'arbre. Si aucune valeur n'est specifier, les nœuds sont développés jusqu'à ce que toutes les feuilles contiennent moins de min_samples_split échantillons.

Dans *Scikit-learn*, optimisation du classificateur d'arbre de décision effectuée uniquement par pré-élagage. La profondeur maximale de l'arbre peut être utilisée comme variable de contrôle pour la pré-élagage. Dans l'exemple suivant, vous pouvez tracer un arbre de décision sur les mêmes données avec *max_depth=3*. Outre les paramètres de pré-élagage, vous pouvez également essayer d'autres mesures de sélection d'attributs telles que l'entropie.
"""

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(criterion="entropy", max_depth=3)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('diabetes.png')
Image(graph.create_png())